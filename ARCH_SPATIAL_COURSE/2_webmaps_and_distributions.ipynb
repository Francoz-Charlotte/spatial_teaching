{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_webmaps_and_distributions.ipynb","version":"0.3.2","provenance":[{"file_id":"1HJB7UGj7YuUEJi-cKZRAr3O4Dlym2KrP","timestamp":1563037636575}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XEKQmmmkiIio","colab_type":"text"},"source":["### Initial Steps\n","\n","Recall from last week: if you haven't already done so: You need your own copy of this notebook. Go to \"File\" and 'save a copy in github' (give access if needed.... put it into the repository you made for this course).\n","\n","Now you have your own copy of the notebook. Click 'open in colab' to get started working on the practical exercise."]},{"cell_type":"markdown","metadata":{"id":"-1zyXWFvOql5","colab_type":"text"},"source":["# Interactive maps and looking more at distributions\n","\n","Last week we focused on making mostly static maps, that is maps where you mostly just expect your user to look at the product you've prepared. \n","\n","This week we'll look at making maps where interactivity is part of the design. \n","\n","We'll also spend some more time on that all important topic: spatial distributions.\n"]},{"cell_type":"markdown","metadata":{"id":"nVvxjDYFOkK8","colab_type":"text"},"source":["### Start by getting tools again."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-11-19T05:33:33.494092Z","start_time":"2018-11-19T05:33:24.204201Z"},"id":"mLiflC-JiIir","colab_type":"code","colab":{}},"source":["#Like last time, get the tools we need at the start\n","import pandas as pd\n","import folium\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TN6AB-EgPF-q","colab_type":"text"},"source":["### And then by getting data\n","\n","This week we are working with the data from the Antikythera survey project.\n","\n","\n","This data has been made available at the Archaeological Data Service (ADS) archive at https://archaeologydataservice.ac.uk/archives/view/antikythera_ahrc_2012/\n","\n","\n","It's citation is: Bevan, A. and Conolly, J. 2012. Intensive Survey Data from Antikythera, Greece. **Journal of Open Archaeology Data** 1(1), DOI: http://dx.doi.org/10.5334/4f3bcb3f7f21d.\n","\n","\n","\n","### Open Data\n","\n","Last week we mentioned open source software. Open data operates under the same broad ethos, and follows many of the same principles. Sharing, reuse, and attribution are key. If you continue to reuse the Antikythera data, be sure to continue to link back to and cite the source.\n","\n","### Working with other people's data\n","\n","Have a quick look around the dataset as it's described on the ADS site. You'll notice that they've split up their dataset in ways that made sense to them at the time. Specifically they've divided up the ceramics and small finds into separate files. This is a pretty normal archaeological data thing to do. \n","\n","Here's the trick. For your purposes, you want to look at both these datasets together. This means you'll have to grab both of them and combine them. This is because you are reusing the data for something new."]},{"cell_type":"code","metadata":{"id":"up4gTxO6Ukzb","colab_type":"code","colab":{}},"source":["#Like last time, get the data we'll need at the start. I've been nice again and converted their coordinates to latitude and longitude for you. \n","#You'll learn to do this yourself later in the course.\n","\n","# we label the first dataset 'pottery'\n","pottery = pd.read_csv('https://raw.githubusercontent.com/ropitz/spatialarchaeology/master/data/antikythera_survey_pottery.csv')\n","\n","# we label the second dataset 'small finds'\n","small_finds = pd.read_csv('https://raw.githubusercontent.com/ropitz/spatialarchaeology/master/data/antikythera_survey_small_finds.csv')\n","\n","# then we combine the two datasets together to make a big dataset we call 'survey data'\n","survey_data = pd.concat([pottery,small_finds], sort=False, ignore_index=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_62uXk_TQwVY","colab_type":"text"},"source":["Now like last week we will use the .head() function to read in the first part of the data and make sure nothing went wrong."]},{"cell_type":"code","metadata":{"id":"pv4XxSSQU2YT","colab_type":"code","colab":{}},"source":["#check things loaded in and combined OK\n","survey_data.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g3MV8nj-VKzB","colab_type":"code","colab":{}},"source":["#You can also check the individual files as well as the combined one we made\n","pottery.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PZqevW03Q4ig","colab_type":"text"},"source":["# Now ask a question\n","\n","Like we said last week, we are using maps and spatial analysis to pose, explore and respond to spatial questions. \n","\n","My question is a bit like last week's question. I want to know about how many sites are in each period, so I can try and understand changingn patterns over time. \n","\n","However, you may have noticed when you read in the data that it's structure is a bit different from last week's data. Instead of each site belonging to one period, it's assinged with varying probability to several different periods. \n","\n","This is a totally legit archaeological thing to do. Many sites have activity from multiple periods, and depending on the available evidence, you might be more or less confident about the presence or absence of activity in a specific period. \n","\n","### So what do we do now?\n","\n","We might start simply by assigning each site primarily to its 'most likely period'. \n","\n","This takes a few steps....\n","\n","### step 1 - prepare the data\n"]},{"cell_type":"code","metadata":{"id":"bbjLzluu1kx9","colab_type":"code","colab":{}},"source":["# first we create a subset of our data that only contains the columns with information about time\n","# this is in part because we want to do some operations where everything has to be a number, and some of the other fields contain text\n","# it's also just to make things simpler when we look at them\n","\n","survey_data_time = survey_data[['MNLN', 'FNEB1',\t'EB2',\t'LPrePal', 'FPal', 'SPal', 'TPal', 'PPalPG', 'Geom', 'Arch', 'Class', 'Hell', 'ERom', 'MRom', 'LRom', 'EByz', 'MByz', 'EVen', 'MVen', 'LVen', 'Recent', 'Other']]\n","survey_data_time.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1P23K0yo2y5U","colab_type":"code","colab":{}},"source":["# if you were to look through this data, you'd see some fields with null values\n","# null values can break number-based operations\n","# let's get rid of null values and make sure everything is a number\n","survey_data_time.astype('float64').fillna(0)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ym3UIQjPZ3Y5","colab_type":"text"},"source":["### step 2 - transform the data\n","\n","Data transformation is an important thing to learn to do.\n","\n","Right now we have a bunch of columns with information about time. \n","\n","What we want is one single column that contains the most likely period - which is represented in each row by the column with the greatest value.\n","\n","*think about that for a moment*\n","\n","Right now the 'most likely period' is represented by a number in each row, but that's not the piece of information we want in our new column - we want the name of the column that contains that number.\n","\n","**Data Transformation describes what we are doing here - reorganizing the data in our table**\n","\n"]},{"cell_type":"code","metadata":{"id":"-VTV0zNi8TBA","colab_type":"code","colab":{}},"source":["#here we take the columns from all the different periods, get the one with the maximum value, and write that column's name to our new 'colmax' field\n","def returncolname(row, colnames):\n","    return colnames[np.argmax(row.values)]\n","\n","survey_data_time['colmax'] = survey_data_time.apply(lambda x: returncolname(x, survey_data_time.columns), axis=1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcza17og5zeo","colab_type":"code","colab":{}},"source":["#we can check it has all gone well\n","survey_data_time.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O5iNwhgraxn9","colab_type":"text"},"source":["## Merging tables\n","\n","OK now we have a single column with the information we need - the most likely date. To create this column, we broke off some of our data (the columns with numbers) from the rest of the data (important descriptive text). We might well want to stick these two datasets back together before proceeding. \n","\n","**splitting and merging tables is another basic skill when working with data**\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"6LxENtT79Rvl","colab_type":"code","colab":{}},"source":["#now we can also add our new column back to our original data table by doing a 'merge'\n","#create a new table 'survey_data_maxtime' by merging our original 'survey_data' with ONLY the 'colmax' column from our new table\n","survey_data_maxtime = pd.merge(survey_data, survey_data_time['colmax'], how='inner', left_index=True, right_index=True)\n","survey_data_maxtime.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8tbZd-bqVx7p","colab_type":"text"},"source":["## The curse of abbreviations\n","\n","Have a look at the resulting table. What do all those column names mean? Right now you are probably justifiably confused. We'll be talking more about the mess that is 'other people's data' next week. For now, have a look at the documentation for these datasets at: https://archaeologydataservice.ac.uk/catalogue/adsdata/arch-1115-2/dissemination/csv/pottery/documentation/pottery.txt\n","\n","You'll see they explain that many of those weird abbreviations are periods and that the number in each one represents the chance that a given find belongs to that period. Sometimes I wish people wouldn't use abbreviations like this, but they've defined them in their metadata file, so we can't compain too much."]},{"cell_type":"markdown","metadata":{"id":"TZeKlPYrbzT3","colab_type":"text"},"source":["## Finally, we make maps!\n","\n","\n","We're going to look at a couple different ways of making maps, because there are lots of tools we can use to do this.\n","\n","### Maps for visualization and interpretation\n","\n","Broadly speaking, there are two ways to approach interpreting spatial patterns. There's vislualization and interpretation, where you might visually compare distributions or densities or locations of two or more datasets by plotting them on a map and intepreting what you see. Then there's statistical analysis. \n","\n","We'll start with the tools to do the first one, and introduce statistical analysis later in the course. \n","\n","We'll also discuss the value of each approach, and when to apply it.\n","\n","### As always, start with a question\n","\n","As we said at the beginning of today, we're interested in change over time.\n","\n","**Analysis Question:**<br>\n","How does the distrubution of finds change between different periods?\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"hYZwq0DesMEw","colab_type":"code","colab":{}},"source":["# we're going to get geopandas, another tool for making maps\n","!pip install geopandas\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_RdAEMkRsl11","colab_type":"code","colab":{}},"source":["# get some more tools for making maps (and other things)\n","\n","%matplotlib inline\n","import geopandas as gpd\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T6MYggBtwUnd","colab_type":"text"},"source":["## Geopandas\n","\n","We're going to introduce a new mapping tool - geopandas. \n","\n","It can do many of the same things as folium, which we were using before.\n","\n","It's particularly useful for showing categorical data. \n","\n","What's categorical data? It's anything where you have a category label, like an archaeological period. \n","\n","We could start tryping to see and understand the distributions of our sites by periods simply by mapping the period labels with different colors.\n"]},{"cell_type":"code","metadata":{"id":"MpBpnIxBrWq6","colab_type":"code","colab":{}},"source":["# take our big dataset from above and turn it from a 'dataframe' which is the data that folium uses to make maps into a 'geodataframe' which is the data geopandas uses to make maps\n","\n","gdf_survey = gpd.GeoDataFrame(\n","    survey_data_maxtime, geometry=gpd.points_from_xy(survey_data_maxtime.DDLon, survey_data_maxtime.DDLat))\n","print(gdf_survey.head())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u6Hmn-KFvz8X","colab_type":"code","colab":{}},"source":["#plot your data colouring the points by the period to which they belong\n","gdf_survey.plot(column='colmax', categorical=True, legend=True, figsize=(15,15))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N0k9G6d0yVPO","colab_type":"text"},"source":["### Assess the resulting map\n","\n","Is it useful? Why or why not?\n","\n","Can you see the distribution of sites from individual periods easily?\n","\n","Can you easily discern change over time?\n","\n","I'm not overly convinced by the result here.\n","\n","What other approach might we take?\n","\n","\n","Let's try something else\n"]},{"cell_type":"code","metadata":{"id":"CZFoGw070Yq_","colab_type":"code","colab":{}},"source":["#Maybe it would be better to only look at two or three periods at a time\n","\n","#let's select a subset of our periods to see change from the early bronze age to hellenistic to late roman\n","\n","types = ['EB2','Hell','LRom']\n","classic = gdf_survey.loc[gdf_survey['colmax'].isin(types)]\n","classic.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROpEOeRw1TZp","colab_type":"code","colab":{}},"source":["#plot your data colouring the points by the period to which they belong\n","classic.plot(column='colmax', categorical=True, legend=True, figsize=(15,15))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VQu68G8o1bDi","colab_type":"text"},"source":["## Thinking about data visualization and map design\n","\n","That's a bit better perhaps. The map is less crowded.\n","\n","Recall our discussions about how to design a map well. Clearly too much data introduces design problems.\n","\n","Well, now we can see the distributions a bit, and maybe say something about change over time, but there are still a lot of dots, and it's pretty clear dots from some periods are hidden under dots from other periods and we have no way to separate them. \n","\n","**what we need here is layers, so we can group our data and work with it interactively**\n","*It would also be nice to have some context for all those dots*\n"]},{"cell_type":"code","metadata":{"id":"C8fCQvSyUrx-","colab_type":"code","colab":{}},"source":["#Like last time, we'll use folium and one of it's plugins\n","from folium.plugins import HeatMapWithTime\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NBXk0ENHiIjR","colab_type":"text"},"source":["### Map Visualizations with Folium"]},{"cell_type":"markdown","metadata":{"id":"wPAgyDlciIjR","colab_type":"text"},"source":["\n","To see the survey data in context and build our interactive maps, we'll start by generating the base map that will be used throughout this notebook.\n","\n","'Basemaps' are generic background maps, like a satellite image or an image of the street map. You know the different backgrounds you can show on google maps? Those are 'basemaps'. \n","\n","Have a look around the web, and you'll see that most modern online maps  use a basemap, so we're going to do so as well.\n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-11-19T05:34:04.673013Z","start_time":"2018-11-19T05:34:04.670120Z"},"id":"0H-uRYF1iIjS","colab_type":"code","colab":{}},"source":["#get the survey area centre, like you did last week, so you can centre the map where the data is located\n","\n","location_survey=survey_data_maxtime['DDLat'].mean(), survey_data_maxtime['DDLon'].mean()\n","print(location_survey)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wUBTM83AbAeX","colab_type":"code","colab":{}},"source":["#define a basemap we can reuse. Use the coordiantes for the centre you generated just above to centre the basemap\n","#This is a variant on how we did things last time...\n","\n","def generateBaseMap(default_location=[35.870086207930626, 23.301798820980512], default_zoom_start=11):\n","    base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start)\n","    return base_map"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4-qIFOBUiIjU","colab_type":"text"},"source":["### Review - basic map controls\n","\n","Arguments:<br><br>\n","location: Define the default location to zoom at when rendering the map<br>\n","zoom_start: The zoom level that the map will default to when rendering the map<br>\n","control_scale: Shows the map scale for a given zoom level"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-11-19T05:34:04.687135Z","start_time":"2018-11-19T05:34:04.674745Z"},"id":"ZhOzNzEEiIjV","colab_type":"code","colab":{}},"source":["#check the basemap is working\n","base_map = generateBaseMap()\n","base_map"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JcHrzMTZxk0b"},"source":[""]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-11-19T06:05:45.764352Z","start_time":"2018-11-19T06:05:45.761769Z"},"id":"--pBpUiviIjc","colab_type":"code","colab":{}},"source":["#lets get the heatmap tool, like last time\n","from folium.plugins import HeatMap\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g-4G4lb9iIje","colab_type":"text"},"source":["Let's start by comparing MRom to LRom, that is middle roman to late roman sites by putting their data in separate layers."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-11-19T05:34:05.037298Z","start_time":"2018-11-19T05:34:04.818915Z"},"id":"2p4cDhYeiIjf","colab_type":"code","colab":{}},"source":["# make a layer for when each period is more than 50% likely, so you have all the sites that are probably in that period\n","survey_data_MRom = survey_data_maxtime.loc[(survey_data_maxtime['MRom'] > 50)]\n","survey_data_ERom = survey_data_maxtime.loc[(survey_data_maxtime['ERom'] > 50)]\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Da1dgQn7fsXx","colab_type":"text"},"source":["### The concept of layers\n","\n","We've introduced a new concept here. Maps have 'layers'. Each layer contains information and can be turned on and off. Think of this like a stack of transparent paper. Each sheet of paper is a layer, and can be added to or taken away from the stack. Their order can also be changed."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-11-19T10:09:37.970112Z","start_time":"2018-11-19T10:09:34.940649Z"},"id":"DxWjo2YUiIjo","colab_type":"code","colab":{}},"source":["# like last time, make heatmaps, but one for each period,  put them in different layers.\n","base_map = generateBaseMap()\n","mrom = HeatMap(data=survey_data_MRom[['DDLat', 'DDLon', 'MRom']].groupby(['DDLat', 'DDLon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n","erom = HeatMap(data=survey_data_ERom[['DDLat', 'DDLon', 'ERom']].groupby(['DDLat', 'DDLon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n","\n","#give the layers sensible names\n","mrom.layer_name = 'Middle Roman Distribution'\n","erom.layer_name = 'Early Roman Distribution'\n","\n","# add the layer control. This is the tool that lets you turn different layers in your map on and off\n","folium.LayerControl().add_to(base_map)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2018-11-19T10:09:48.682799Z","start_time":"2018-11-19T10:09:39.486706Z"},"id":"mzgBodwBiIjr","colab_type":"code","colab":{}},"source":["#Now generate your map by calling it by its name\n","base_map"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wSCv-r8eXuXE","colab_type":"text"},"source":["Now try and add some more layers to the map to show other periods!"]},{"cell_type":"code","metadata":{"id":"engTEEWWe454","colab_type":"code","colab":{}},"source":["# make a layer for when the max period is LRom or MRom to compare these periods\n","survey_data_lrommax = survey_data_maxtime.loc[(survey_data_maxtime['colmax'] =='LRom')]\n","survey_data_mrommax = survey_data_maxtime.loc[(survey_data_maxtime['colmax'] =='MRom')]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_ucaKUkfW_F","colab_type":"code","colab":{}},"source":["\n","# like last time, make heatmaps, but one for each period,  put them in different layers\n","base_map = generateBaseMap()\n","\n","lrommax = HeatMap(data=survey_data_lrommax[['DDLat', 'DDLon']].groupby(['DDLat', 'DDLon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n","mrommax = HeatMap(data=survey_data_mrommax[['DDLat', 'DDLon']].groupby(['DDLat', 'DDLon']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n","\n","#give the layers sensible names\n","lrommax.layer_name = 'Late Roman Distribution'\n","mrommax.layer_name = 'Middle Roman Distribution'\n","\n","# add the layer control\n","folium.LayerControl().add_to(base_map)\n","base_map\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZYz4hI_1kImv","colab_type":"text"},"source":["## visualization and interpretation\n","\n","Thought exercise: The results of these two maps should be similar but slightly different. What is making the difference?\n","\n","How good are you at interpreting these distributions and comparing them visually?\n","\n","*This is me hinting at you that you are going to end up wanting to use statistics eventually*\n"]},{"cell_type":"markdown","metadata":{"id":"XWAQRddKcogi","colab_type":"text"},"source":[" \n","\n","# Think about basic principles\n","\n","The principles of what we've done this week are the same as the principles of what we did last week. \n","\n","I think it's important to learn to do things more than one way, and to adapt to slightly different tools. The software and code packages used for modern spatial analysis and mapping are pretty diverse and are always developing as people improve things. It doesn't make much sense to just learn one way of making maps mechanistically. The important thing is to understand the principles of what you're doing. \n","\n","In any code package that is meant to be used for making maps, odds are good you will find a way to set the zoom level, set the centre starting location, and set the initial scale. \n","\n","You will be able to set up colour schemes, map attributes, and make layers. Knowing keywords and princples is the important thing. "]},{"cell_type":"markdown","metadata":{"id":"3ZCz_MQuj8ZF","colab_type":"text"},"source":["## The End\n","\n","That's all for today. Be sure to save your copy of the notebook in your own repo so I can see it!"]}]}